#! /usr/bin/env python3
# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved

# Storms SQS images queue with messages which will be inferred as S3 uploads
# by the pdq_hasher lambda. Given a bucket and a prefix, gets files in that
# bucket, for each creates SQS messages and rotates through that list until it
# has published enough messages.

# If the bucket with the prefix has more than 1000 keys, only the first 1000
# keys returned are used.

# $ ./storm_images_queue <queue_url> <s3_bucket> <prefix> <count>
# Example
# $ ./storm_images_queue https://queue.amazonaws.com/<acid>/<queue_name> <bucket_name> images/10MB/ 100000

SQS_BATCH_SIZE = 10 # matches the batch size in s3 subscription

def unleash_storm(
    queue_url: str,
    s3_bucket: str,
    s3_prefix: str,
    msg_count: int
):
    s3_client = boto3.client('s3')

    # Obtain the images
    response = s3_client.list_objects_v2(
        Bucket=s3_bucket,
        Prefix=s3_prefix,
    )

    images = list(map(lambda x: x['Key'], response['Contents']))
    image_chunks = [images[i:i + SQS_BATCH_SIZE] for i in range(0, len(images), SQS_BATCH_SIZE)]

    sqs_client = boto3.client('sqs')

    sent_batch_count = 0
    sent_message_count = 0
    while True:
        current_chunk = image_chunks[sent_batch_count % len(image_chunks)]

        # Process one chunk begin
        sqs_client.send_message_batch(
            QueueUrl=queue_url,
            Entries=[{
                        'Id': f'message-{sent_batch_count}-{i}',
                        'MessageBody': """{"Message": "{\\\"Records\\\": [{\\\"s3\\\": {\\\"s3SchemaVersion\\\": \\\"1.0\\\",\\\"bucket\\\": {\\\"name\\\": \\\"%s\\\"},\\\"object\\\": {\\\"key\\\": \\\"%s\\\",\\\"size\\\": 12}}}]}"}""" % (s3_bucket, image)
                    } for i, image in enumerate(current_chunk)]
        )
        # Process one chunk ends

        sent_message_count += len(current_chunk)
        sent_batch_count += 1

        if sent_message_count > msg_count:
            break

    print(f"Sent {sent_message_count} messages in {sent_batch_count} batches")

if __name__ == "__main__":
    import sys

    # Do import checks
    try:
        import boto3
    except ModuleNotFoundError:
        print(f"{sys.argv[0]} requires boto3 to be on PYTHONPATH")
        sys.exit(1)

    queue_url = sys.argv[1]
    s3_bucket = sys.argv[2]
    s3_prefix = sys.argv[3]
    msg_count = int(sys.argv[4])

    unleash_storm(queue_url, s3_bucket, s3_prefix, msg_count)
