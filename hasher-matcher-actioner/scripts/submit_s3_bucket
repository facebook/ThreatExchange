#! /usr/bin/env python3
# Copyright (c) Meta Platforms, Inc. and affiliates.

"""
Given an S3 bucket, and enough permissions on the credentials, iterates through
all items and submits them as presigned URLs to HMA.

Run without arguments for help.

Requires you have AWS credentials to 'get_object' from the bucket passed to the script.    
Example usage:
$ ./scripts/submit_s3_bucket --token `cat .authtoken` --prefix "<redacted/s3-object/prefix/>" --api_url https://<redacted>.execute-api.us-east-1.amazonaws.com/ --storm <redacted_bucketname> 

"""

import uuid
import argparse
import typing as t
import boto3
import functools
import concurrent.futures

from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry

from hmalib.scripts.common.utils import HasherMatcherActionerAPI


@functools.lru_cache(maxsize=None)
def _get_s3_client():
    return boto3.client("s3")


@functools.lru_cache(maxsize=None)
def _get_hma_api(api_url, token):
    retry_strategy = Retry(
        total=5,
        backoff_factor=1,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=[
            "GET",
            "PUT",
            "POST",
        ],  # Including POST as the API should not perform an insert if an error is returned
    )
    api = HasherMatcherActionerAPI(
        api_url, token, transport_adapter=HTTPAdapter(max_retries=retry_strategy)
    )
    return api


class S3BucketSubmitter:
    def __init__(
        self,
        bucket: str,
        api: HasherMatcherActionerAPI,
        prefix: t.Optional[str] = None,
        storm: bool = False,
    ):
        self.bucket = bucket
        self.prefix = prefix
        self.api = api
        self.storm = storm

    def map_object_presigned_urls(self, callable: t.Callable):
        paginator = _get_s3_client().get_paginator("list_objects_v2")
        pages = paginator.paginate(Bucket=self.bucket, Prefix=self.prefix)

        for page in pages:
            for object in page["Contents"]:
                if object["Size"] == 0:
                    # Ignore folders and empty files
                    continue

                presigned_url = _get_s3_client().generate_presigned_url(
                    "get_object",
                    Params={
                        "Bucket": self.bucket,
                        "Key": object["Key"],
                    },
                    ExpiresIn=3 * 60 * 60,  # 3 hours from now.
                )
                callable(presigned_url)

    def run(self):
        # max_workers = 60 gave 14k / minute from a docker container with 8 gigs of ram and 8 vCPUs
        # max_workers = 40 gave 15k / minute from a docker container " "
        # max_workers = 20 gave me 9.6k / minute from a docker container  " "
        with concurrent.futures.ThreadPoolExecutor(max_workers=60) as executor:
            if self.storm:
                i = 0
                while True:
                    i += 1
                    self.run_one_iteration(executor)
                    print(f"Submitted {i} batches.")
            else:
                self.run_one_iteration()

    def run_one_iteration(self, executor):
        def submit_one(presigned_url: str):
            content_id = str(uuid.uuid4())
            executor.submit(self.api.submit_via_external_url, content_id, presigned_url)

        self.map_object_presigned_urls(submit_one)


def get_argparser():
    parser = argparse.ArgumentParser(
        description="List files in an s3 bucket and submit them to the submissions API using presigned URLs"
    )
    parser.add_argument(
        "bucket_name",
        help="S3 Bucket Name. Must not contain the s3:// protocol scheme eg. hma-test-media",
    )
    parser.add_argument(
        "--token",
        help="Authorization token obtained using get_auth_token",
        required=True,
    )
    parser.add_argument(
        "--prefix",
        help="S3 prefix to narrow down which objects you want to submit.",
        required=False,
    )
    parser.add_argument(
        "--api_url",
        help="The Base URL of API gateway that you want to submit to. eg. https://mc620fy2hf.execute-api.us-east-1.amazonaws.com/",
        required=True,
    )
    parser.add_argument(
        "--storm",
        action="store_true",
        help="Loop over the same set of S3 objects and submit copies until Ctrl-C'd.",
    )
    return parser


if __name__ == "__main__":
    parser = get_argparser()
    args = parser.parse_args()

    api = _get_hma_api(args.api_url, args.token)

    submitter = S3BucketSubmitter(
        args.bucket_name, api, prefix=args.prefix, storm=args.storm
    )
    submitter.run()
